{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6277,"databundleVersionId":323734,"sourceType":"competition"},{"sourceId":9398439,"sourceType":"datasetVersion","datasetId":5704515}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-15T07:57:47.638467Z","iopub.execute_input":"2024-09-15T07:57:47.639223Z","iopub.status.idle":"2024-09-15T07:57:47.999316Z","shell.execute_reply.started":"2024-09-15T07:57:47.639177Z","shell.execute_reply":"2024-09-15T07:57:47.998429Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/quoradata/train.csv\n/kaggle/input/quoradata/test.csv\n/kaggle/input/quora-question-pairs/train.csv.zip\n/kaggle/input/quora-question-pairs/sample_submission.csv.zip\n/kaggle/input/quora-question-pairs/test.csv\n/kaggle/input/quora-question-pairs/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-09-15T07:58:09.829503Z","iopub.execute_input":"2024-09-15T07:58:09.830487Z","iopub.status.idle":"2024-09-15T07:58:24.066795Z","shell.execute_reply.started":"2024-09-15T07:58:09.830440Z","shell.execute_reply":"2024-09-15T07:58:24.065689Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.0)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.24.6)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.3->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.1.0-py3-none-any.whl (249 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install ipywidgets --upgrade\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T08:19:12.175051Z","iopub.execute_input":"2024-09-15T08:19:12.175418Z","iopub.status.idle":"2024-09-15T08:19:25.970216Z","shell.execute_reply.started":"2024-09-15T08:19:12.175383Z","shell.execute_reply":"2024-09-15T08:19:25.969070Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nCollecting ipywidgets\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nCollecting widgetsnbextension~=4.0.12 (from ipywidgets)\n  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\nDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.8\n    Uninstalling widgetsnbextension-3.6.8:\n      Successfully uninstalled widgetsnbextension-3.6.8\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab_widgets 3.0.11\n    Uninstalling jupyterlab_widgets-3.0.11:\n      Successfully uninstalled jupyterlab_widgets-3.0.11\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-09-15T08:19:38.006784Z","iopub.execute_input":"2024-09-15T08:19:38.007195Z","iopub.status.idle":"2024-09-15T08:19:50.885203Z","shell.execute_reply.started":"2024-09-15T08:19:38.007155Z","shell.execute_reply":"2024-09-15T08:19:50.884069Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom sentence_transformers import evaluation, util\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\n# Load the Quora question pairs dataset\ndf = pd.read_csv('/kaggle/input/quoradata/train.csv')\n\n# Preprocess and select a subset\ndf = df[['question1', 'question2', 'is_duplicate']].dropna()\n\n# Split into train and test sets (keeping test set constant)\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Create train and test examples\ntrain_samples = [InputExample(texts=[row['question1'], row['question2']], label=row['is_duplicate']) for _, row in train_df.iterrows()]\ntest_samples = [(row['question1'], row['question2'], row['is_duplicate']) for _, row in test_df.iterrows()]\n\n# DataLoader for training\ntrain_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T08:19:55.916455Z","iopub.execute_input":"2024-09-15T08:19:55.917254Z","iopub.status.idle":"2024-09-15T08:20:24.633947Z","shell.execute_reply.started":"2024-09-15T08:19:55.917200Z","shell.execute_reply":"2024-09-15T08:20:24.633116Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Model for the Bi-encoder (off-the-shelf)\nbi_encoder_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n\n# Loss function options\ndef train_model(model, loss_fn):\n    # Define loss and train the model\n    train_loss = loss_fn(model=model)\n    model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)\n    return model\n\n# Cosine Similarity Loss\ncosine_loss_fn = losses.CosineSimilarityLoss\ncosine_model = train_model(bi_encoder_model, cosine_loss_fn)\n\n# Contrastive Loss\ncontrastive_loss_fn = losses.ContrastiveLoss\ncontrastive_model = train_model(bi_encoder_model, contrastive_loss_fn)\n\n# Multiple Negative Ranking Loss\nmnr_loss_fn = losses.MultipleNegativesRankingLoss\nmnr_model = train_model(bi_encoder_model, mnr_loss_fn)\n\n# Cross-encoder model\ncross_encoder_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\ncross_encoder_loss_fn = losses.ContrastiveLoss\ncross_encoder = train_model(cross_encoder_model, cross_encoder_loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T08:20:33.661812Z","iopub.execute_input":"2024-09-15T08:20:33.662217Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240915_082111-fk679kg5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vanshika1413-svkm-s-narsee-monjee-institute-of-managemen/sentence-transformers/runs/fk679kg5' target=\"_blank\">checkpoints/model_1</a></strong> to <a href='https://wandb.ai/vanshika1413-svkm-s-narsee-monjee-institute-of-managemen/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vanshika1413-svkm-s-narsee-monjee-institute-of-managemen/sentence-transformers' target=\"_blank\">https://wandb.ai/vanshika1413-svkm-s-narsee-monjee-institute-of-managemen/sentence-transformers</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vanshika1413-svkm-s-narsee-monjee-institute-of-managemen/sentence-transformers/runs/fk679kg5' target=\"_blank\">https://wandb.ai/vanshika1413-svkm-s-narsee-monjee-institute-of-managemen/sentence-transformers/runs/fk679kg5</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7630' max='10108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 7630/10108 28:32 < 09:16, 4.45 it/s, Epoch 0.75/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.169900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.145600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.139300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.131900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.129600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.127200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.126300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.126100</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.120100</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.116600</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.119900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.117600</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.116100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.113900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.111500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"# Test the models and calculate F1-Score\ndef evaluate_model(model, test_data):\n    y_true, y_pred = [], []\n    for q1, q2, label in test_data:\n        emb1 = model.encode(q1)\n        emb2 = model.encode(q2)\n        sim = util.pytorch_cos_sim(emb1, emb2)  # Cosine similarity\n        y_true.append(label)\n        y_pred.append(1 if sim >= 0.5 else 0)\n    return f1_score(y_true, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the models\nf1_cosine = evaluate_model(cosine_model, test_samples)\nf1_contrastive = evaluate_model(contrastive_model, test_samples)\nf1_mnr = evaluate_model(mnr_model, test_samples)\nf1_cross = evaluate_model(cross_encoder, test_samples)\n\n# Print F1-scores\nprint(f\"F1-Score for Cosine Similarity Model: {f1_cosine}\")\nprint(f\"F1-Score for Contrastive Model: {f1_contrastive}\")\nprint(f\"F1-Score for Multiple Negatives Ranking Model: {f1_mnr}\")\nprint(f\"F1-Score for Cross Encoder Model: {f1_cross}\")\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare off-the-shelf vs fine-tuned\noff_shelf_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\nf1_off_shelf = evaluate_model(off_shelf_model, test_samples)\nprint(f\"F1-Score for Off-the-Shelf Model: {f1_off_shelf}\")","metadata":{},"execution_count":null,"outputs":[]}]}