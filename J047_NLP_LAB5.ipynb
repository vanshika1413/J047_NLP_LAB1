{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9241808,"sourceType":"datasetVersion","datasetId":5590453},{"sourceId":9243600,"sourceType":"datasetVersion","datasetId":5591651}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T12:04:46.773549Z","iopub.execute_input":"2024-08-25T12:04:46.773856Z","iopub.status.idle":"2024-08-25T12:04:47.155427Z","shell.execute_reply.started":"2024-08-25T12:04:46.773822Z","shell.execute_reply":"2024-08-25T12:04:47.154325Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:47:15.833736Z","iopub.execute_input":"2024-08-25T10:47:15.834779Z","iopub.status.idle":"2024-08-25T10:47:30.669560Z","shell.execute_reply.started":"2024-08-25T10:47:15.834701Z","shell.execute_reply":"2024-08-25T10:47:30.668290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/imdb-dataset/IMDB Dataset.csv\").rename(columns={\"review\": \"text\"})","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:02.022509Z","iopub.execute_input":"2024-08-25T12:24:02.022908Z","iopub.status.idle":"2024-08-25T12:24:02.589696Z","shell.execute_reply.started":"2024-08-25T12:24:02.022868Z","shell.execute_reply":"2024-08-25T12:24:02.588487Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**ROBERT**","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn import model_selection, metrics","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:04.521634Z","iopub.execute_input":"2024-08-25T12:24:04.522034Z","iopub.status.idle":"2024-08-25T12:24:04.528304Z","shell.execute_reply.started":"2024-08-25T12:24:04.521995Z","shell.execute_reply":"2024-08-25T12:24:04.527194Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Configuration settings\nconfig = {\n    \"max_length\": 360,\n    \"model_path\": \"FacebookAI/roberta-base\",  # Use RoBERTa model\n    \"output_dir\": \"./roberta-model\",\n    \"train_batch_size\": 32,  # Adjusted batch size\n    \"valid_batch_size\": 32,\n    \"learning_rate\": 2e-5,  # Adjusted learning rate\n    \"epochs\": 4,  # Increased epochs\n    \"debug\": True,\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:08.000855Z","iopub.execute_input":"2024-08-25T12:24:08.001766Z","iopub.status.idle":"2024-08-25T12:24:08.008742Z","shell.execute_reply.started":"2024-08-25T12:24:08.001723Z","shell.execute_reply":"2024-08-25T12:24:08.007564Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Dataset class\nclass TextDataset:\n    def __init__(self, data, tokenizer, max_length):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        enc = self.tokenizer.encode_plus(\n            row[\"text\"],\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n        return {\n            \"input_ids\": enc[\"input_ids\"].squeeze(),\n            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n            \"label\": torch.tensor(row[\"label\"]),\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:10.184607Z","iopub.execute_input":"2024-08-25T12:24:10.184988Z","iopub.status.idle":"2024-08-25T12:24:10.194448Z","shell.execute_reply.started":"2024-08-25T12:24:10.184952Z","shell.execute_reply":"2024-08-25T12:24:10.193482Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"id2label = {0: \"negative\", 1: \"positive\"}\nlabel2id = {label: id_ for id_, label in id2label.items()}\n\ndf[\"label\"] = df[\"sentiment\"].map(label2id)\n\nif config[\"debug\"]:\n    print(\"DEBUG MODE!\")\n    df = df.sample(1000, random_state=123)\n\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:12.201261Z","iopub.execute_input":"2024-08-25T12:24:12.201890Z","iopub.status.idle":"2024-08-25T12:24:12.235839Z","shell.execute_reply.started":"2024-08-25T12:24:12.201848Z","shell.execute_reply":"2024-08-25T12:24:12.234866Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"DEBUG MODE!\n(1000, 3)\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment  label\n11872  This movie was beyond awful, it was a pimple o...  negative      0\n40828  As of this writing John Carpenter's 'Halloween...  positive      1\n36400  I must admit a slight disappointment with this...  positive      1\n5166   Oh dear! The BBC is not about to be knocked of...  negative      0\n30273  its a totally average film with a few semi-alr...  negative      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11872</th>\n      <td>This movie was beyond awful, it was a pimple o...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40828</th>\n      <td>As of this writing John Carpenter's 'Halloween...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36400</th>\n      <td>I must admit a slight disappointment with this...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5166</th>\n      <td>Oh dear! The BBC is not about to be knocked of...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30273</th>\n      <td>its a totally average film with a few semi-alr...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(config[\"model_path\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:15.389269Z","iopub.execute_input":"2024-08-25T12:24:15.390187Z","iopub.status.idle":"2024-08-25T12:24:15.640280Z","shell.execute_reply.started":"2024-08-25T12:24:15.390119Z","shell.execute_reply":"2024-08-25T12:24:15.639160Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train, valid = model_selection.train_test_split(\n    df,\n    test_size=0.2,\n    random_state=123,\n    shuffle=True,\n    stratify=df[\"label\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:17.498898Z","iopub.execute_input":"2024-08-25T12:24:17.499317Z","iopub.status.idle":"2024-08-25T12:24:17.508905Z","shell.execute_reply.started":"2024-08-25T12:24:17.499279Z","shell.execute_reply":"2024-08-25T12:24:17.507976Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train_ds = TextDataset(train, tokenizer, config[\"max_length\"])\nvalid_ds = TextDataset(valid, tokenizer, config[\"max_length\"])\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\n    config[\"model_path\"],\n    num_labels=len(id2label)\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:19.257413Z","iopub.execute_input":"2024-08-25T12:24:19.257882Z","iopub.status.idle":"2024-08-25T12:24:19.504488Z","shell.execute_reply.started":"2024-08-25T12:24:19.257835Z","shell.execute_reply":"2024-08-25T12:24:19.498437Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)  # Get the predicted labels from logits\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n    acc = accuracy_score(labels, predictions)\n    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:21.437684Z","iopub.execute_input":"2024-08-25T12:24:21.438082Z","iopub.status.idle":"2024-08-25T12:24:21.445875Z","shell.execute_reply.started":"2024-08-25T12:24:21.438044Z","shell.execute_reply":"2024-08-25T12:24:21.444810Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"training_args = transformers.TrainingArguments(\n    output_dir=config[\"output_dir\"],\n    num_train_epochs=config[\"epochs\"],\n    per_device_train_batch_size=config[\"train_batch_size\"],\n    per_device_eval_batch_size=config[\"valid_batch_size\"],\n    learning_rate=config[\"learning_rate\"],\n    evaluation_strategy=\"steps\",  # Evaluate every few steps\n    eval_steps=500,  # Adjust the number of steps for evaluation\n    save_strategy=\"steps\",  # Save model every few steps\n    save_steps=500,  # Ensure it aligns with eval_steps\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    logging_dir=\"./logs\",\n    logging_steps=100,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:23.235915Z","iopub.execute_input":"2024-08-25T12:24:23.236613Z","iopub.status.idle":"2024-08-25T12:24:23.268425Z","shell.execute_reply.started":"2024-08-25T12:24:23.236571Z","shell.execute_reply":"2024-08-25T12:24:23.267589Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = transformers.Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=valid_ds,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:25.191602Z","iopub.execute_input":"2024-08-25T12:24:25.192428Z","iopub.status.idle":"2024-08-25T12:24:25.385949Z","shell.execute_reply.started":"2024-08-25T12:24:25.192386Z","shell.execute_reply":"2024-08-25T12:24:25.384869Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:24:27.266034Z","iopub.execute_input":"2024-08-25T12:24:27.266929Z","iopub.status.idle":"2024-08-25T12:26:28.475302Z","shell.execute_reply.started":"2024-08-25T12:24:27.266888Z","shell.execute_reply":"2024-08-25T12:26:28.474399Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 01:56, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7/7 00:02]\n    </div>\n    "},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.3309495449066162,\n 'eval_accuracy': 0.875,\n 'eval_f1': 0.8768472906403942,\n 'eval_precision': 0.8725490196078431,\n 'eval_recall': 0.8811881188118812,\n 'eval_runtime': 2.6401,\n 'eval_samples_per_second': 75.756,\n 'eval_steps_per_second': 2.651,\n 'epoch': 4.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"**BERT**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:12:25.110627Z","iopub.execute_input":"2024-08-25T12:12:25.111286Z","iopub.status.idle":"2024-08-25T12:12:25.127321Z","shell.execute_reply.started":"2024-08-25T12:12:25.111247Z","shell.execute_reply":"2024-08-25T12:12:25.126275Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"model_path\": \"bert-base-uncased\",  # Use BERT model\n    \"output_dir\": \"./bert-model\",  # Output directory for the model\n    \"train_batch_size\": 8,  # Adjusted batch size\n    \"valid_batch_size\": 8,\n    \"learning_rate\": 2e-5,  # Learning rate\n    \"epochs\": 3,  # Number of epochs\n    \"max_length\": 360,\n    \"debug\": True,\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:12:26.808834Z","iopub.execute_input":"2024-08-25T12:12:26.809603Z","iopub.status.idle":"2024-08-25T12:12:26.816074Z","shell.execute_reply.started":"2024-08-25T12:12:26.809562Z","shell.execute_reply":"2024-08-25T12:12:26.814686Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:12:29.541338Z","iopub.execute_input":"2024-08-25T12:12:29.541729Z","iopub.status.idle":"2024-08-25T12:12:33.344264Z","shell.execute_reply.started":"2024-08-25T12:12:29.541693Z","shell.execute_reply":"2024-08-25T12:12:33.343205Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2381c112ed0042a9a594fb9732a0504d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49770cc7694d4ce787b43d4b7f17021c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1807da960ad24cd19bd3d2a0e1472df2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9853dc731dc4ac98a71d0ca04d57c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4d9ab2c4fc4dbcae4978b0d16ce61c"}},"metadata":{}},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/imdb-dataset/IMDB Dataset.csv\").rename(columns={\"review\": \"text\", \"sentiment\": \"label\"})\ndf['label'] = df['label'].apply(lambda x: 1 if x == \"positive\" else 0)\n\nif config[\"debug\"]:\n    df = df.sample(1000, random_state=42) ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:13:44.434059Z","iopub.execute_input":"2024-08-25T12:13:44.434449Z","iopub.status.idle":"2024-08-25T12:13:45.112941Z","shell.execute_reply.started":"2024-08-25T12:13:44.434414Z","shell.execute_reply":"2024-08-25T12:13:45.111813Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example['text'], padding=\"max_length\", truncation=True, max_length=config['max_length'])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:13:46.570383Z","iopub.execute_input":"2024-08-25T12:13:46.570786Z","iopub.status.idle":"2024-08-25T12:13:46.577714Z","shell.execute_reply.started":"2024-08-25T12:13:46.570749Z","shell.execute_reply":"2024-08-25T12:13:46.576669Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Dataset Conversion and Tokenization\ndataset = Dataset.from_pandas(df)\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:13:47.829715Z","iopub.execute_input":"2024-08-25T12:13:47.830107Z","iopub.status.idle":"2024-08-25T12:13:57.558303Z","shell.execute_reply.started":"2024-08-25T12:13:47.830069Z","shell.execute_reply":"2024-08-25T12:13:57.557239Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc28415fdad420e92d0216d73d6b00a"}},"metadata":{}}]},{"cell_type":"code","source":"train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\ntrain_dataset = train_test_split['train']\ntest_dataset = train_test_split['test']\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:14:06.174843Z","iopub.execute_input":"2024-08-25T12:14:06.175223Z","iopub.status.idle":"2024-08-25T12:14:06.193342Z","shell.execute_reply.started":"2024-08-25T12:14:06.175186Z","shell.execute_reply":"2024-08-25T12:14:06.192434Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)  # Get the predicted labels from logits\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n    acc = accuracy_score(labels, predictions)\n    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:20:51.298068Z","iopub.execute_input":"2024-08-25T12:20:51.298945Z","iopub.status.idle":"2024-08-25T12:20:51.306258Z","shell.execute_reply.started":"2024-08-25T12:20:51.298905Z","shell.execute_reply":"2024-08-25T12:20:51.305031Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=config['output_dir'],\n    evaluation_strategy=\"epoch\",\n    learning_rate=config['learning_rate'],\n    per_device_train_batch_size=config['train_batch_size'],\n    per_device_eval_batch_size=config['valid_batch_size'],\n    num_train_epochs=config['epochs'],\n    weight_decay=0.01,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:20:52.589206Z","iopub.execute_input":"2024-08-25T12:20:52.589609Z","iopub.status.idle":"2024-08-25T12:20:52.620869Z","shell.execute_reply.started":"2024-08-25T12:20:52.589566Z","shell.execute_reply":"2024-08-25T12:20:52.620062Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:20:58.159972Z","iopub.execute_input":"2024-08-25T12:20:58.160811Z","iopub.status.idle":"2024-08-25T12:20:58.177213Z","shell.execute_reply.started":"2024-08-25T12:20:58.160775Z","shell.execute_reply":"2024-08-25T12:20:58.176192Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:21:00.307246Z","iopub.execute_input":"2024-08-25T12:21:00.308087Z","iopub.status.idle":"2024-08-25T12:22:51.399318Z","shell.execute_reply.started":"2024-08-25T12:21:00.308045Z","shell.execute_reply":"2024-08-25T12:22:51.398370Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 01:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.480553</td>\n      <td>0.910000</td>\n      <td>0.901099</td>\n      <td>0.953488</td>\n      <td>0.854167</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.467462</td>\n      <td>0.905000</td>\n      <td>0.898396</td>\n      <td>0.923077</td>\n      <td>0.875000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.478899</td>\n      <td>0.910000</td>\n      <td>0.906250</td>\n      <td>0.906250</td>\n      <td>0.906250</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:02]\n    </div>\n    "},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.4788985848426819,\n 'eval_accuracy': 0.91,\n 'eval_f1': 0.90625,\n 'eval_precision': 0.90625,\n 'eval_recall': 0.90625,\n 'eval_runtime': 2.5331,\n 'eval_samples_per_second': 78.955,\n 'eval_steps_per_second': 9.869,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}