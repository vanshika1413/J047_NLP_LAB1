{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MJZTT0M4ThZg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "1JQ6xnvBa32P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x1gohEiV1bu",
        "outputId": "0807985a-64f9-446f-ed7e-b3a8911b7e4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "GluiMXrjUmyB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure you have the stopwords downloaded\n",
        "import nltk\n",
        "# 1. Text Cleaning\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['review'].apply(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aObKFAZzUygz",
        "outputId": "17e9acff-accc-46a0-b66e-5009d5b80042"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
      ],
      "metadata": {
        "id": "MpH7h_J1Uylf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "b3bk3Tb2Uypi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Frequency-Based Vectors (CountVectorizer)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_counts = vectorizer.fit_transform(train_df['cleaned_text'])\n",
        "X_test_counts = vectorizer.transform(test_df['cleaned_text'])"
      ],
      "metadata": {
        "id": "2u0qUYcsUyrK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Word Vectors (Word2Vec)\n",
        "tokenized_corpus = [word_tokenize(text) for text in train_df['cleaned_text']]\n",
        "w2v_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "w2v_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL-eOM7tUytl",
        "outputId": "5369e973-0715-4d20-bcb2-c6a764305f50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46377323, 48637980)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a text to a Word2Vec vector\n",
        "def text_to_w2v(text, model, vector_size):\n",
        "    words = word_tokenize(text)\n",
        "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
        "    if len(word_vecs) == 0:\n",
        "        return torch.zeros(vector_size)\n",
        "    return torch.tensor(sum(word_vecs) / len(word_vecs))\n",
        "\n",
        "train_w2v = torch.stack([text_to_w2v(text, w2v_model, 100) for text in train_df['cleaned_text']])\n",
        "test_w2v = torch.stack([text_to_w2v(text, w2v_model, 100) for text in test_df['cleaned_text']])"
      ],
      "metadata": {
        "id": "UF92iZ33UywS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Custom Dataset for DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = TextDataset(train_w2v, torch.tensor(train_df['label'].values))\n",
        "test_dataset = TextDataset(test_w2v, torch.tensor(test_df['label'].values))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "WPpXUec1Uyy1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(glove_file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_file_path = '/content/glove.6B.100d.txt'\n",
        "embeddings_index = load_glove_embeddings(glove_file_path)\n",
        "\n",
        "# Create an embedding matrix\n",
        "embedding_dim = 100\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "embedding_matrix = np.zeros((vocab_size + 1, embedding_dim))\n",
        "\n",
        "for word, i in vectorizer.vocabulary_.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "1iFmyL5MUy1e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, tokenized_texts, labels, vectorizer, max_len=100):\n",
        "        self.tokenized_texts = tokenized_texts\n",
        "        self.labels = labels\n",
        "        self.vectorizer = vectorizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenized_texts[idx]\n",
        "        # Convert tokens to their corresponding indices using the vectorizer's vocabulary\n",
        "        indices = [self.vectorizer.vocabulary_.get(token, 0) for token in tokens]\n",
        "        # Pad or truncate sequences to the max length\n",
        "        if len(indices) > self.max_len:\n",
        "            indices = indices[:self.max_len]\n",
        "        else:\n",
        "            indices = indices + [0] * (self.max_len - len(indices))\n",
        "\n",
        "        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "# Reuse the existing tokenized corpus and labels\n",
        "train_dataset = IMDBDataset(tokenized_corpus, train_df['label'].values, vectorizer)\n",
        "test_tokenized_corpus = [word_tokenize(text) for text in test_df['cleaned_text']]\n",
        "test_dataset = IMDBDataset(test_tokenized_corpus, test_df['label'].values, vectorizer)\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "lC9sWHGVUy3z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Model using GloVe Embeddings with Vanilla RNN"
      ],
      "metadata": {
        "id": "0t9QhxjgaGA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU and use it if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, output_dim, n_layers=1):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        out = self.fc(hidden[-1])\n",
        "        return out\n",
        "\n",
        "# Initialize the RNN model with GloVe embeddings\n",
        "hidden_dim = 128\n",
        "output_dim = 2  # Positive or Negative\n",
        "rnn_model = RNNClassifier(embedding_matrix, hidden_dim, output_dim)\n",
        "\n",
        "# Move the model to the GPU\n",
        "rnn_model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the RNN model\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move inputs and labels to the GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "train_model(rnn_model, criterion, optimizer, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNz6RVRJYcee",
        "outputId": "3ecf99f7-86cf-4968-f8d1-8215d8741505"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.6838019123792648\n",
            "Epoch 2/10, Loss: 0.6853447044372558\n",
            "Epoch 3/10, Loss: 0.6501961549520493\n",
            "Epoch 4/10, Loss: 0.6092361849546433\n",
            "Epoch 5/10, Loss: 0.594579152417183\n",
            "Epoch 6/10, Loss: 0.5422507105827331\n",
            "Epoch 7/10, Loss: 0.512430697774887\n",
            "Epoch 8/10, Loss: 0.4693398876309395\n",
            "Epoch 9/10, Loss: 0.4523708668589592\n",
            "Epoch 10/10, Loss: 0.4720785665273666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Model using GloVe Embeddings with LSTM"
      ],
      "metadata": {
        "id": "6lbqxbM7aKgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU and use it if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, output_dim, n_layers=1):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, _) = self.lstm(embedded)\n",
        "        out = self.fc(hidden[-1])\n",
        "        return out\n",
        "\n",
        "# Initialize the LSTM model with GloVe embeddings\n",
        "hidden_dim = 128\n",
        "output_dim = 2  # Positive or Negative\n",
        "lstm_model = LSTMClassifier(embedding_matrix, hidden_dim, output_dim)\n",
        "\n",
        "# Move the model to the GPU\n",
        "lstm_model.to(device)\n",
        "\n",
        "# Define loss function and optimizer for LSTM\n",
        "lstm_criterion = nn.CrossEntropyLoss()\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the LSTM model\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move inputs and labels to the GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "train_model(lstm_model, lstm_criterion, lstm_optimizer, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7MmRXBQZsRQ",
        "outputId": "01e60ed1-4d71-4c72-ca05-0bd40352dda6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.5901321661949158\n",
            "Epoch 2/10, Loss: 0.28092729479670525\n",
            "Epoch 3/10, Loss: 0.11972991601675749\n",
            "Epoch 4/10, Loss: 0.038710661563975735\n",
            "Epoch 5/10, Loss: 0.01279011968499981\n",
            "Epoch 6/10, Loss: 0.005521329668955878\n",
            "Epoch 7/10, Loss: 0.002706246008859307\n",
            "Epoch 8/10, Loss: 0.0015360830800178519\n",
            "Epoch 9/10, Loss: 0.0016554665244926583\n",
            "Epoch 10/10, Loss: 0.0006381060961397452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Models using On-the-Fly Embeddings with Vanilla RNN and LSTM"
      ],
      "metadata": {
        "id": "bIAxSWv4aNNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU and use it if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class OnTheFlyRNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1):\n",
        "        super(OnTheFlyRNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        out = self.fc(hidden[-1])\n",
        "        return out\n",
        "\n",
        "# Initialize the RNN model with on-the-fly embeddings\n",
        "hidden_dim = 128\n",
        "output_dim = 2  # Positive or Negative\n",
        "on_the_fly_rnn_model = OnTheFlyRNNClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Move the model to the GPU\n",
        "on_the_fly_rnn_model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "on_the_fly_rnn_criterion = nn.CrossEntropyLoss()\n",
        "on_the_fly_rnn_optimizer = optim.Adam(on_the_fly_rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the RNN model\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move inputs and labels to the GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "train_model(on_the_fly_rnn_model, on_the_fly_rnn_criterion, on_the_fly_rnn_optimizer, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl9v2GGDZ9Fg",
        "outputId": "2c4c528c-7ead-4d5c-8b9b-c79c552583d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.6987871993541718\n",
            "Epoch 2/10, Loss: 0.6943235644817353\n",
            "Epoch 3/10, Loss: 0.6839151214122772\n",
            "Epoch 4/10, Loss: 0.6513142557621002\n",
            "Epoch 5/10, Loss: 0.6287366610527039\n",
            "Epoch 6/10, Loss: 0.6362035749673843\n",
            "Epoch 7/10, Loss: 0.5885704596042634\n",
            "Epoch 8/10, Loss: 0.5670207745790482\n",
            "Epoch 9/10, Loss: 0.5839957120895386\n",
            "Epoch 10/10, Loss: 0.5346727333784104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On-the-Fly Embeddings with LSTM"
      ],
      "metadata": {
        "id": "vy8wowL5aPXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU and use it if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class OnTheFlyLSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1):\n",
        "        super(OnTheFlyLSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, _) = self.lstm(embedded)\n",
        "        out = self.fc(hidden[-1])\n",
        "        return out\n",
        "\n",
        "# Initialize the LSTM model with on-the-fly embeddings\n",
        "hidden_dim = 128\n",
        "output_dim = 2  # Positive or Negative\n",
        "on_the_fly_lstm_model = OnTheFlyLSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Move the model to the GPU\n",
        "on_the_fly_lstm_model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "on_the_fly_lstm_criterion = nn.CrossEntropyLoss()\n",
        "on_the_fly_lstm_optimizer = optim.Adam(on_the_fly_lstm_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the LSTM model\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move inputs and labels to the GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "train_model(on_the_fly_lstm_model, on_the_fly_lstm_criterion, on_the_fly_lstm_optimizer, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3p4T66jZ-iL",
        "outputId": "36ae5805-2191-4842-d51b-0f32a561de8a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.6751812165260315\n",
            "Epoch 2/10, Loss: 0.4971581143260002\n",
            "Epoch 3/10, Loss: 0.2973037529051304\n",
            "Epoch 4/10, Loss: 0.1981917773529887\n",
            "Epoch 5/10, Loss: 0.11875437894165516\n",
            "Epoch 6/10, Loss: 0.06724135623089969\n",
            "Epoch 7/10, Loss: 0.03911319843754172\n",
            "Epoch 8/10, Loss: 0.025700910528050736\n",
            "Epoch 9/10, Loss: 0.01734880520249717\n",
            "Epoch 10/10, Loss: 0.011303001155995298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing and Evaluation"
      ],
      "metadata": {
        "id": "xV2yTMnxaXc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in test_loader:\n",
        "            # Move inputs and labels to the GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate each model on the test dataset\n",
        "print(\"Evaluating RNN Model with GloVe Embeddings\")\n",
        "evaluate_model(rnn_model, test_loader)\n",
        "\n",
        "print(\"Evaluating LSTM Model with GloVe Embeddings\")\n",
        "evaluate_model(lstm_model, test_loader)\n",
        "\n",
        "print(\"Evaluating On-the-Fly RNN Model\")\n",
        "evaluate_model(on_the_fly_rnn_model, test_loader)\n",
        "\n",
        "print(\"Evaluating On-the-Fly LSTM Model\")\n",
        "evaluate_model(on_the_fly_lstm_model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq03Vwa9aDfP",
        "outputId": "219165f1-a622-4aee-95af-02600e020e54"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RNN Model with GloVe Embeddings\n",
            "Accuracy: 58.46%\n",
            "Evaluating LSTM Model with GloVe Embeddings\n",
            "Accuracy: 84.24%\n",
            "Evaluating On-the-Fly RNN Model\n",
            "Accuracy: 57.52%\n",
            "Evaluating On-the-Fly LSTM Model\n",
            "Accuracy: 85.21%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.21"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K95GQRa-gtb2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}